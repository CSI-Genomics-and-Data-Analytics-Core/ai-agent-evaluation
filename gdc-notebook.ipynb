{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b23ca5c",
   "metadata": {},
   "source": [
    "# GDC Query Evaluation Framework\n",
    "\n",
    "This notebook evaluates 30 queries across three complexity levels against the Genomic Data Commons (GDC) API:\n",
    "- **Basic Discovery (Low Complexity)**: 10 queries (EV-L01 to EV-L10)\n",
    "- **Entity Filtering (Medium Complexity)**: 10 queries (EV-M01 to EV-M10)  \n",
    "- **Complex Cohorts (High Complexity)**: 10 queries (EV-H01 to EV-H10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df95ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4adb8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GDC API Configuration\n",
    "GDC_API_BASE = \"https://api.gdc.cancer.gov\"\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3a73fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def graphql_query(query, variables=None):\n",
    "    \"\"\"Execute GraphQL query against GDC\"\"\"\n",
    "    url = f\"{GDC_API_BASE}/v0/graphql\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    payload = {\"query\": query}\n",
    "    if variables:\n",
    "        payload[\"variables\"] = variables\n",
    "\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "    # Better error handling\n",
    "    if response.status_code != 200:\n",
    "        print(f\"❌ GraphQL Error: {response.status_code}\")\n",
    "        print(f\"Response: {response.text}\")\n",
    "        return None\n",
    "\n",
    "    result = response.json()\n",
    "    if \"errors\" in result:\n",
    "        print(f\"❌ GraphQL Errors: {json.dumps(result['errors'], indent=2)}\")\n",
    "        return None\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def rest_query(endpoint, params=None):\n",
    "    \"\"\"Execute REST API query against GDC\"\"\"\n",
    "    url = f\"{GDC_API_BASE}/{endpoint}\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e34c250b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ EV-L01 Failed: HTTPSConnectionPool(host='api.gdc.cancer.gov', port=443): Max retries exceeded with url: /projects?size=2000&fields=program.name (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x10e8a8430>: Failed to establish a new connection: [Errno 51] Network is unreachable'))\n"
     ]
    }
   ],
   "source": [
    "# EV-L01: In the GDC database, list all available program names\n",
    "# Direct entity list (program names)\n",
    "def eval_L01():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        # Get programs through projects endpoint since programs endpoint doesn't exist\n",
    "        result = rest_query(\"projects\", {\n",
    "            \"size\": \"2000\",\n",
    "            \"fields\": \"program.name\"\n",
    "        })\n",
    "        \n",
    "        # Extract unique program names\n",
    "        programs = set()\n",
    "        for project in result[\"data\"][\"hits\"]:\n",
    "            program_info = project.get(\"program\", {})\n",
    "            if isinstance(program_info, dict) and \"name\" in program_info:\n",
    "                programs.add(program_info[\"name\"])\n",
    "            elif isinstance(program_info, list):\n",
    "                for prog in program_info:\n",
    "                    if isinstance(prog, dict) and \"name\" in prog:\n",
    "                        programs.add(prog[\"name\"])\n",
    "        \n",
    "        programs_list = sorted(list(programs))\n",
    "        count = len(programs_list)\n",
    "        \n",
    "        print(f\"✅ EV-L01: Found {count} programs\")\n",
    "        print(f\"Programs: {', '.join(programs_list)}\")\n",
    "        \n",
    "        results[\"EV-L01\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"{count} programs\",\n",
    "            \"data\": programs_list,\n",
    "            \"time\": time.time() - start,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-L01 Failed: {e}\")\n",
    "        results[\"EV-L01\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_L01()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c3cb7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ EV-L02 Failed: HTTPSConnectionPool(host='api.gdc.cancer.gov', port=443): Max retries exceeded with url: /projects?size=0 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x10e8aa8c0>: Failed to establish a new connection: [Errno 51] Network is unreachable'))\n"
     ]
    }
   ],
   "source": [
    "# EV-L02: In the GDC database, count the total number of projects\n",
    "# Simple count (total projects)\n",
    "def eval_L02():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        result = rest_query(\"projects\", {\"size\": \"0\"})\n",
    "        count = result[\"data\"][\"pagination\"][\"total\"]\n",
    "        \n",
    "        print(f\"✅ EV-L02: Found {count} projects\")\n",
    "        \n",
    "        results[\"EV-L02\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"{count} projects\",\n",
    "            \"time\": time.time() - start,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-L02 Failed: {e}\")\n",
    "        results[\"EV-L02\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_L02()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56687c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EV-L03: Found 69 primary sites (excluding '_missing')\n",
      "Sites: Accessory sinuses; Adrenal gland; Anus and anal canal; Base of tongue; Bladder; Bones, joints and articular cartilage of limbs; Bones, joints and articular cartilage of other and unspecified sites; Brain; Breast; Bronchus and lung; Cervix uteri; Colon; Connective, subcutaneous and other soft tissues; Corpus uteri; Esophagus; Eye and adnexa; Floor of mouth; Gallbladder; Gum; Heart, mediastinum, and pleura; Hematopoietic and reticuloendothelial systems; Hypopharynx; Kidney; Larynx; Lip; Liver and intrahepatic bile ducts; Lymph nodes; Meninges; Nasal cavity and middle ear; Nasopharynx; Not Reported; Oropharynx; Other and ill-defined digestive organs; Other and ill-defined sites; Other and ill-defined sites in lip, oral cavity and pharynx; Other and ill-defined sites within respiratory system and intrathoracic organs; Other and unspecified female genital organs; Other and unspecified major salivary glands; Other and unspecified male genital organs; Other and unspecified parts of biliary tract; Other and unspecified parts of mouth; Other and unspecified parts of tongue; Other and unspecified urinary organs; Other endocrine glands and related structures; Ovary; Palate; Pancreas; Parotid gland; Penis; Peripheral nerves and autonomic nervous system; Prostate gland; Rectosigmoid junction; Rectum; Renal pelvis; Retroperitoneum and peritoneum; Skin; Small intestine; Spinal cord, cranial nerves, and other parts of central nervous system; Stomach; Testis; Thymus; Thyroid gland; Tonsil; Trachea; Unknown; Ureter; Uterus, NOS; Vagina; Vulva\n"
     ]
    }
   ],
   "source": [
    "# EV-L03: In the GDC database, retrieve the primary sites represented across all projects\n",
    "# Basic metadata retrieval (primary sites)\n",
    "def eval_L03():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        result = rest_query(\"projects\", {\n",
    "            \"size\": \"2000\",\n",
    "            \"fields\": \"primary_site\"\n",
    "        })\n",
    "        \n",
    "        primary_sites = set()\n",
    "        for project in result[\"data\"][\"hits\"]:\n",
    "            sites = project.get(\"primary_site\", [])\n",
    "            if isinstance(sites, list):\n",
    "                for site in sites:\n",
    "                    if site and site != \"_missing\":  # Exclude _missing values\n",
    "                        primary_sites.add(site)\n",
    "            elif sites and sites != \"_missing\":  # Exclude _missing values\n",
    "                primary_sites.add(sites)\n",
    "        \n",
    "        count = len(primary_sites)\n",
    "        sorted_sites = sorted(primary_sites)\n",
    "        \n",
    "        print(f\"✅ EV-L03: Found {count} primary sites (excluding '_missing')\")\n",
    "        print(f\"Sites: {'; '.join(sorted_sites)}\")\n",
    "        \n",
    "        results[\"EV-L03\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"{count} primary sites\",\n",
    "            \"data\": sorted_sites,\n",
    "            \"time\": time.time() - start\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-L03 Failed: {e}\")\n",
    "        results[\"EV-L03\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_L03()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b2bea05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EV-L04: Found 11 data categories\n",
      "Categories: biospecimen; clinical; combined nucleotide variation; copy number variation; dna methylation; proteome profiling; sequencing reads; simple nucleotide variation; somatic structural variation; structural variation; transcriptome profiling\n"
     ]
    }
   ],
   "source": [
    "# EV-L04: In the GDC database, list all data categories (e.g., Raw Sequencing Data, Transcriptome Profiling)\n",
    "# Single-field lookup (data categories)\n",
    "def eval_L04():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        result = rest_query(\"files\", {\n",
    "            \"size\": \"0\",\n",
    "            \"facets\": \"data_category\"\n",
    "        })\n",
    "        \n",
    "        categories = []\n",
    "        for bucket in result[\"data\"][\"aggregations\"][\"data_category\"][\"buckets\"]:\n",
    "            categories.append(bucket[\"key\"])\n",
    "        \n",
    "        count = len(categories)\n",
    "        print(f\"✅ EV-L04: Found {count} data categories\")\n",
    "        print(f\"Categories: {'; '.join(sorted(categories))}\")\n",
    "        \n",
    "        results[\"EV-L04\"] = {\n",
    "            \"status\": \"success\", \n",
    "            \"result\": f\"{count} data categories\",\n",
    "            \"data\": sorted(categories),\n",
    "            \"time\": time.time() - start\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-L04 Failed: {e}\")\n",
    "        results[\"EV-L04\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_L04()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8ddcd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EV-L05: Found 13 experimental strategies (excluding '_missing')\n",
      "Strategies: ATAC-Seq; Diagnostic Slide; Expression Array; Genotyping Array; Methylation Array; RNA-Seq; Reverse Phase Protein Array; Targeted Sequencing; Tissue Slide; WGS; WXS; miRNA-Seq; scRNA-Seq\n"
     ]
    }
   ],
   "source": [
    "# EV-L05: In the GDC database, get all experimental strategies used\n",
    "# Direct enumeration (experimental strategies)\n",
    "def eval_L05():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        result = rest_query(\"files\", {\n",
    "            \"size\": \"0\",\n",
    "            \"facets\": \"experimental_strategy\"\n",
    "        })\n",
    "        \n",
    "        strategies = []\n",
    "        for bucket in result[\"data\"][\"aggregations\"][\"experimental_strategy\"][\"buckets\"]:\n",
    "            strategy = bucket[\"key\"]\n",
    "            if strategy and strategy != \"_missing\":  # Exclude _missing values\n",
    "                strategies.append(strategy)\n",
    "        \n",
    "        count = len(strategies)\n",
    "        print(f\"✅ EV-L05: Found {count} experimental strategies (excluding '_missing')\")\n",
    "        print(f\"Strategies: {'; '.join(sorted(strategies))}\")\n",
    "        \n",
    "        results[\"EV-L05\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"{count} experimental strategies\", \n",
    "            \"data\": sorted(strategies),\n",
    "            \"time\": time.time() - start\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-L05 Failed: {e}\")\n",
    "        results[\"EV-L05\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_L05()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1498dbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EV-L06: Found 233,388 RNA-Seq files across all projects\n"
     ]
    }
   ],
   "source": [
    "# EV-L06: In the GDC database, count the total number of RNA-Seq files across all projects\n",
    "# Single filter condition (experimental_strategy = RNA-Seq)\n",
    "def eval_L06():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        filters = {\n",
    "            \"op\": \"=\",\n",
    "            \"content\": {\n",
    "                \"field\": \"experimental_strategy\",\n",
    "                \"value\": \"RNA-Seq\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        result = rest_query(\"files\", {\n",
    "            \"filters\": json.dumps(filters),\n",
    "            \"size\": \"0\"\n",
    "        })\n",
    "        \n",
    "        count = result[\"data\"][\"pagination\"][\"total\"]\n",
    "        print(f\"✅ EV-L06: Found {count:,} RNA-Seq files across all projects\")\n",
    "        \n",
    "        results[\"EV-L06\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"{count} RNA-Seq files\",\n",
    "            \"time\": time.time() - start\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-L06 Failed: {e}\")\n",
    "        results[\"EV-L06\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_L06()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "386053f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EV-L07: Found 35 annotation categories\n",
      "Categories: acceptable treatment for tcga tumor; alternate sample pipeline; barcode incorrect; bcr notification; biospecimen identity unknown; case submitted is found to be a recurrence after submission; center qc failed; duplicate case; duplicate item; general; genotype mismatch; history of acceptable prior treatment related to a prior/other malignancy; history of unacceptable prior treatment related to a prior/other malignancy; inadvertently shipped; item does not meet study protocol; item flagged dnu; item flagged low quality; item in special subset; item is noncanonical; item may not meet study protocol; molecular analysis outside specification; neoadjuvant therapy; normal class but appears diseased; normal tissue origin incorrect; pathology outside specification; permanently missing item or object; prior malignancy; qualification metrics changed; qualified in error; sample compromised; subject identity unknown; subject withdrew consent; synchronous malignancy; tumor class but appears normal; tumor tissue origin incorrect\n"
     ]
    }
   ],
   "source": [
    "# EV-L07: In the GDC database, list all annotation categories\n",
    "# Simple lookup (annotation categories)\n",
    "def eval_L07():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        result = rest_query(\"annotations\", {\n",
    "            \"size\": \"0\",\n",
    "            \"facets\": \"category\"\n",
    "        })\n",
    "        \n",
    "        categories = []\n",
    "        \n",
    "        for bucket in result[\"data\"][\"aggregations\"][\"category\"][\"buckets\"]:\n",
    "            categories.append(bucket[\"key\"])\n",
    "        \n",
    "        print(f\"✅ EV-L07: Found {len(categories)} annotation categories\")\n",
    "        print(f\"Categories: {'; '.join(sorted(categories))}\")\n",
    "        \n",
    "        results[\"EV-L07\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"{len(categories)} annotation categories\",\n",
    "            \"data\": {\"categories\": sorted(categories)},\n",
    "            \"time\": time.time() - start\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-L07 Failed: {e}\")\n",
    "        results[\"EV-L07\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_L07()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2d96808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EV-L08: Found 48 disease types\n",
      "Disease types: acinar cell neoplasms; acute lymphoblastic leukemia; adenomas and adenocarcinomas; adnexal and skin appendage neoplasms; basal cell neoplasms; blood vessel tumors; chronic myeloproliferative disorders; complex epithelial neoplasms; complex mixed and stromal neoplasms; cystic, mucinous and serous neoplasms; ductal and lobular neoplasms; epithelial neoplasms, nos; fibroepithelial neoplasms; fibromatous neoplasms; germ cell neoplasms; gliomas; granular cell tumors and alveolar soft part sarcomas; leukemias, nos; lipomatous neoplasms; lymphoid leukemias; malignant lymphomas, nos or diffuse; mature b-cell lymphomas; mature t- and nk-cell lymphomas; meningiomas; mesothelial neoplasms; miscellaneous bone tumors; miscellaneous tumors; mucoepidermoid neoplasms; myelodysplastic syndromes; myeloid leukemias; myomatous neoplasms; neoplasms, nos; nerve sheath tumors; neuroepitheliomatous neoplasms; nevi and melanomas; not applicable; not reported; odontogenic tumors; osseous and chondromatous neoplasms; paragangliomas and glomus tumors; plasma cell tumors; soft tissue tumors and sarcomas, nos; specialized gonadal neoplasms; squamous cell neoplasms; synovial-like neoplasms; thymic epithelial neoplasms; transitional cell papillomas and carcinomas; unknown\n"
     ]
    }
   ],
   "source": [
    "# EV-L08: In the GDC database, list all the available disease types\n",
    "def eval_L08():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        result = rest_query(\"cases\", {\n",
    "            \"size\": \"0\",\n",
    "            \"facets\": \"disease_type\"\n",
    "        })\n",
    "        \n",
    "        disease_types = []\n",
    "        for bucket in result[\"data\"][\"aggregations\"][\"disease_type\"][\"buckets\"]:\n",
    "            disease_type = bucket[\"key\"]\n",
    "            if disease_type and disease_type != \"_missing\":  # Exclude _missing values\n",
    "                disease_types.append(disease_type)\n",
    "        \n",
    "        count = len(disease_types)\n",
    "        print(f\"✅ EV-L08: Found {count} disease types\")\n",
    "        print(f\"Disease types: {'; '.join(sorted(disease_types))}\")\n",
    "        \n",
    "        results[\"EV-L08\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"{count} disease types\",\n",
    "            \"data\": sorted(disease_types),\n",
    "            \"time\": time.time() - start,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-L08 Failed: {e}\")\n",
    "        results[\"EV-L08\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_L08()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6d9d179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EV-L09: Found 4 ethnicity categories\n",
      "Ethnicities: hispanic or latino; not hispanic or latino; not reported; unknown\n"
     ]
    }
   ],
   "source": [
    "# EV-L09: In the GDC database, list the available ethnicity categories\n",
    "# Single-field enumeration (ethnicity categories)\n",
    "def eval_L09():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        result = rest_query(\"cases\", {\n",
    "            \"size\": \"0\",\n",
    "            \"facets\": \"demographic.ethnicity\"\n",
    "        })\n",
    "        \n",
    "        ethnicities = []\n",
    "        for bucket in result[\"data\"][\"aggregations\"][\"demographic.ethnicity\"][\"buckets\"]:\n",
    "            ethnicity = bucket[\"key\"]\n",
    "            if ethnicity and ethnicity != \"_missing\":  # Exclude _missing values\n",
    "                ethnicities.append(ethnicity)\n",
    "        \n",
    "        count = len(ethnicities)\n",
    "        print(f\"✅ EV-L09: Found {count} ethnicity categories\")\n",
    "        print(f\"Ethnicities: {'; '.join(sorted(ethnicities))}\")\n",
    "        \n",
    "        results[\"EV-L09\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"{count} ethnicity categories\",\n",
    "            \"data\": sorted(ethnicities),\n",
    "            \"time\": time.time() - start\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-L09 Failed: {e}\")\n",
    "        results[\"EV-L09\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_L09()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f54bb21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EV-L10: Found 10 platform types (excluding '_missing')\n",
      "  illumina: 799,977\n",
      "  affymetrix snp 6.0: 147,734\n",
      "  illumina human methylation 450: 31,776\n",
      "  illumina methylation epic: 18,522\n",
      "  illumina human methylation 27: 9,435\n",
      "  rppa: 7,906\n",
      "  genechip u133a: 1,243\n",
      "  illumina methylation epic v2: 1,179\n",
      "  complete genomics: 581\n",
      "  genechip u133 plus 2.0: 183\n"
     ]
    }
   ],
   "source": [
    "# EV-L10: In the GDC database, what are the available platform types used for sequencing\n",
    "# Basic metadata with counts (platform types)\n",
    "def eval_L10():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        result = rest_query(\"files\", {\n",
    "            \"size\": \"0\",\n",
    "            \"facets\": \"platform\"\n",
    "        })\n",
    "        \n",
    "        platforms = []\n",
    "        platform_counts = {}\n",
    "        for bucket in result[\"data\"][\"aggregations\"][\"platform\"][\"buckets\"]:\n",
    "            platform = bucket[\"key\"]\n",
    "            count = bucket[\"doc_count\"]\n",
    "            if platform and platform != \"_missing\":  # Exclude _missing values\n",
    "                platforms.append(platform)\n",
    "                platform_counts[platform] = count\n",
    "        \n",
    "        total_platforms = len(platforms)\n",
    "        print(f\"✅ EV-L10: Found {total_platforms} platform types (excluding '_missing')\")\n",
    "        \n",
    "        # Show top platforms by count\n",
    "        sorted_platforms = sorted(platform_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        for platform, count in sorted_platforms[:10]:\n",
    "            print(f\"  {platform}: {count:,}\")\n",
    "        \n",
    "        results[\"EV-L10\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"{total_platforms} platform types\",\n",
    "            \"data\": {\"platforms\": platforms, \"counts\": platform_counts},\n",
    "            \"time\": time.time() - start,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-L10 Failed: {e}\")\n",
    "        results[\"EV-L10\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_L10()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93de2cc0",
   "metadata": {},
   "source": [
    "### ENTITY FILTERING QUERIES (Medium Complexity)\n",
    "\n",
    "These queries apply specific filtering criteria to narrow down results within one or two entity types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37fceaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EV-M01: TCGA-LUAD gender distribution:\n",
      "  Females: 280\n",
      "  Males: 242\n"
     ]
    }
   ],
   "source": [
    "# EV-M01: In the GDC database, count male vs. female cases in TCGA-LUAD\n",
    "# Cross-entity filter with faceting (project + gender)\n",
    "def eval_M01():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        filters = {\n",
    "            \"op\": \"=\",\n",
    "            \"content\": {\n",
    "                \"field\": \"project.project_id\",\n",
    "                \"value\": \"TCGA-LUAD\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        result = rest_query(\"cases\", {\n",
    "            \"filters\": json.dumps(filters),\n",
    "            \"size\": \"0\",\n",
    "            \"facets\": \"demographic.gender\"\n",
    "        })\n",
    "        \n",
    "        gender_counts = {}\n",
    "        for bucket in result[\"data\"][\"aggregations\"][\"demographic.gender\"][\"buckets\"]:\n",
    "            gender_counts[bucket[\"key\"]] = bucket[\"doc_count\"]\n",
    "        \n",
    "        females = gender_counts.get(\"female\", 0)\n",
    "        males = gender_counts.get(\"male\", 0)\n",
    "        \n",
    "        print(f\"✅ EV-M01: TCGA-LUAD gender distribution:\")\n",
    "        print(f\"  Females: {females}\")\n",
    "        print(f\"  Males: {males}\")\n",
    "        \n",
    "        results[\"EV-M01\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"{females} females, {males} males\",\n",
    "            \"data\": gender_counts,\n",
    "            \"time\": time.time() - start,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-M01 Failed: {e}\")\n",
    "        results[\"EV-M01\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_M01()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a54899f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EV-M02: Race distribution for TCGA-LIHC (377 total cases):\n",
      "  white: 187 (49.60%)\n",
      "  asian: 161 (42.71%)\n",
      "  black or african american: 17 (4.51%)\n",
      "  not reported: 6 (1.59%)\n",
      "  unknown: 4 (1.06%)\n",
      "  american indian or alaska native: 2 (0.53%)\n"
     ]
    }
   ],
   "source": [
    "# EV-M02: In the GDC database, show the race distribution for TCGA-LIHC\n",
    "# Project-specific demographic distribution\n",
    "def eval_M02():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        filters = {\n",
    "            \"op\": \"=\",\n",
    "            \"content\": {\n",
    "                \"field\": \"project.project_id\",\n",
    "                \"value\": \"TCGA-LIHC\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        result = rest_query(\"cases\", {\n",
    "            \"filters\": json.dumps(filters),\n",
    "            \"size\": \"0\",\n",
    "            \"facets\": \"demographic.race\"\n",
    "        })\n",
    "        \n",
    "        # Get race distribution\n",
    "        race_counts = {}\n",
    "        total_cases = 0\n",
    "        for bucket in result[\"data\"][\"aggregations\"][\"demographic.race\"][\"buckets\"]:\n",
    "            race = bucket[\"key\"]\n",
    "            count = bucket[\"doc_count\"]\n",
    "            race_counts[race] = count\n",
    "            total_cases += count\n",
    "        \n",
    "        print(f\"✅ EV-M02: Race distribution for TCGA-LIHC ({total_cases} total cases):\")\n",
    "        for race, count in sorted(race_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "            percentage = (count / total_cases) * 100 if total_cases > 0 else 0\n",
    "            print(f\"  {race}: {count} ({percentage:.2f}%)\")\n",
    "        \n",
    "        results[\"EV-M02\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"Race distribution for TCGA-LIHC\",\n",
    "            \"data\": race_counts,\n",
    "            \"time\": time.time() - start\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-M02 Failed: {e}\")\n",
    "        results[\"EV-M02\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_M02()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49db27ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EV-M03: Found 86 TCGA-LUAD cases with Stage III variants\n",
      "  Individual counts:\n",
      "    Stage III: 1\n",
      "    Stage IIIA: 74\n",
      "    Stage IIIB: 11\n"
     ]
    }
   ],
   "source": [
    "# EV-M03: In the GDC database, count cases diagnosed at any Stage III variant (Stage III, Stage IIIA, Stage IIIB) in the TCGA-LUAD project\n",
    "# OR logic across multiple stage values with individual counts\n",
    "def eval_M03():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        stage_variants = [\"Stage III\", \"Stage IIIA\", \"Stage IIIB\"]\n",
    "        filters = {\n",
    "            \"op\": \"and\",\n",
    "            \"content\": [\n",
    "                {\"op\": \"=\", \"content\": {\"field\": \"project.project_id\", \"value\": \"TCGA-LUAD\"}},\n",
    "                {\n",
    "                    \"op\": \"in\",\n",
    "                    \"content\": {\n",
    "                        \"field\": \"diagnoses.ajcc_pathologic_stage\",\n",
    "                        \"value\": stage_variants\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Get total count and breakdown by stage\n",
    "        result = rest_query(\"cases\", {\n",
    "            \"filters\": json.dumps(filters),\n",
    "            \"size\": \"0\",\n",
    "            \"facets\": \"diagnoses.ajcc_pathologic_stage\"\n",
    "        })\n",
    "        \n",
    "        total_count = result[\"data\"][\"pagination\"][\"total\"]\n",
    "        \n",
    "        # Get individual counts for each stage variant\n",
    "        stage_counts = {stage.lower().replace(\" \", \" \"): 0 for stage in stage_variants}\n",
    "        for bucket in result[\"data\"][\"aggregations\"][\"diagnoses.ajcc_pathologic_stage\"][\"buckets\"]:\n",
    "            stage = bucket[\"key\"]\n",
    "            count = bucket[\"doc_count\"]\n",
    "            # Match against our target stages (case-insensitive)\n",
    "            if \"iiia\" in stage.lower():\n",
    "                stage_counts[\"Stage IIIA\"] = count\n",
    "            elif \"iiib\" in stage.lower():\n",
    "                stage_counts[\"Stage IIIB\"] = count\n",
    "            elif stage.lower() == \"stage iii\":\n",
    "                stage_counts[\"Stage III\"] = count\n",
    "        \n",
    "        print(f\"✅ EV-M03: Found {total_count} TCGA-LUAD cases with Stage III variants\")\n",
    "        print(f\"  Individual counts:\")\n",
    "        for stage in stage_variants:\n",
    "            count = stage_counts.get(stage, 0)\n",
    "            print(f\"    {stage}: {count}\")\n",
    "        \n",
    "        results[\"EV-M03\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"{total_count} TCGA-LUAD Stage III cases\",\n",
    "            \"data\": {\"total\": total_count, \"stage_counts\": stage_counts},\n",
    "            \"time\": time.time() - start\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-M03 Failed: {e}\")\n",
    "        results[\"EV-M03\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_M03()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "726cbc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EV-M04: Found 69 TCGA-LUAD cases with tumor stage T3 or T4\n",
      "  Individual counts:\n",
      "    T3: 50\n",
      "    T4: 19\n"
     ]
    }
   ],
   "source": [
    "# EV-M04: In the GDC database, count cases with tumor stage T3 or T4 in the TCGA-LUAD project\n",
    "# OR logic on tumor stage field\n",
    "def eval_M04():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        filters = {\n",
    "            \"op\": \"and\",\n",
    "            \"content\": [\n",
    "                {\"op\": \"=\", \"content\": {\"field\": \"project.project_id\", \"value\": \"TCGA-LUAD\"}},\n",
    "                {\n",
    "                    \"op\": \"in\",\n",
    "                    \"content\": {\n",
    "                        \"field\": \"diagnoses.ajcc_pathologic_t\",\n",
    "                        \"value\": [\"T3\", \"T4\"]\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        result = rest_query(\"cases\", {\n",
    "            \"filters\": json.dumps(filters),\n",
    "            \"size\": \"0\",\n",
    "            \"facets\": \"diagnoses.ajcc_pathologic_t\"\n",
    "        })\n",
    "        \n",
    "        count = result[\"data\"][\"pagination\"][\"total\"]\n",
    "        \n",
    "        # Get individual counts for T3 and T4\n",
    "        stage_counts = {}\n",
    "        for bucket in result[\"data\"][\"aggregations\"][\"diagnoses.ajcc_pathologic_t\"][\"buckets\"]:\n",
    "            stage = bucket[\"key\"]\n",
    "            if stage.lower() in [\"t3\", \"t4\"]:\n",
    "                stage_counts[stage.upper()] = bucket[\"doc_count\"]\n",
    "        \n",
    "        print(f\"✅ EV-M04: Found {count} TCGA-LUAD cases with tumor stage T3 or T4\")\n",
    "        print(f\"  Individual counts:\")\n",
    "        print(f\"    T3: {stage_counts.get('T3', 0)}\")\n",
    "        print(f\"    T4: {stage_counts.get('T4', 0)}\")\n",
    "        \n",
    "        results[\"EV-M04\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"{count} TCGA-LUAD T3/T4 cases\",\n",
    "            \"data\": {\"total\": count, \"stage_counts\": stage_counts},\n",
    "            \"time\": time.time() - start,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-M04 Failed: {e}\")\n",
    "        results[\"EV-M04\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_M04()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "337f6176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EV-M05: Found 4256 WXS files > 10GB in CPTAC-3\n"
     ]
    }
   ],
   "source": [
    "# EV-M05: In the GDC database, count WXS files that are larger than 10 GB (10,737,418,240 bytes) in the CPTAC-3 project\n",
    "# Multiple filters (project + experimental_strategy + file_size)\n",
    "def eval_M05():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        filters = {\n",
    "            \"op\": \"and\",\n",
    "            \"content\": [\n",
    "                {\"op\": \"=\", \"content\": {\"field\": \"cases.project.project_id\", \"value\": \"CPTAC-3\"}},\n",
    "                {\"op\": \"=\", \"content\": {\"field\": \"experimental_strategy\", \"value\": \"WXS\"}},\n",
    "                {\"op\": \">\", \"content\": {\"field\": \"file_size\", \"value\": 10737418240}}  # 10 GB in bytes\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        result = rest_query(\"files\", {\n",
    "            \"filters\": json.dumps(filters),\n",
    "            \"size\": \"0\"\n",
    "        })\n",
    "        \n",
    "        count = result[\"data\"][\"pagination\"][\"total\"]\n",
    "        print(f\"✅ EV-M05: Found {count} WXS files > 10GB in CPTAC-3\")\n",
    "        \n",
    "        results[\"EV-M05\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"{count} WXS files > 10GB\",\n",
    "            \"time\": time.time() - start\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-M05 Failed: {e}\")\n",
    "        results[\"EV-M05\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_M05()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0edae4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EV-M06: Found 1632 cases with primary site 'Bronchus and lung' AND age > 70 years\n"
     ]
    }
   ],
   "source": [
    "# EV-M06: In the GDC database, count cases with primary site 'Bronchus and lung' AND age at diagnosis greater than 70 years (25,550 days)\n",
    "# Two simultaneous filters (site + age calculation)\n",
    "def eval_M06():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        filters = {\n",
    "            \"op\": \"and\",\n",
    "            \"content\": [\n",
    "                {\"op\": \"in\", \"content\": {\"field\": \"primary_site\", \"value\": [\"Bronchus and lung\"]}},\n",
    "                {\"op\": \">\", \"content\": {\"field\": \"diagnoses.age_at_diagnosis\", \"value\": 25550}}  # 70 years in days\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        result = rest_query(\"cases\", {\n",
    "            \"filters\": json.dumps(filters),\n",
    "            \"size\": \"0\"\n",
    "        })\n",
    "        \n",
    "        count = result[\"data\"][\"pagination\"][\"total\"]\n",
    "        print(f\"✅ EV-M06: Found {count} cases with primary site 'Bronchus and lung' AND age > 70 years\")\n",
    "        \n",
    "        results[\"EV-M06\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"{count} lung cases with age > 70\",\n",
    "            \"time\": time.time() - start\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-M06 Failed: {e}\")\n",
    "        results[\"EV-M06\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_M06()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9bff4739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EV-M07: Found 154 TCGA-OV cases with days_to_death < 1000\n"
     ]
    }
   ],
   "source": [
    "# EV-M07: In the GDC database, count the number of cases from the TCGA-OV project where the patient died within less than 1000 days\n",
    "# Range-based filtering (project + days_to_death < 1000)\n",
    "def eval_M07():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        filters = {\n",
    "            \"op\": \"and\",\n",
    "            \"content\": [\n",
    "                {\"op\": \"=\", \"content\": {\"field\": \"project.project_id\", \"value\": \"TCGA-OV\"}},\n",
    "                {\"op\": \"<\", \"content\": {\"field\": \"demographic.days_to_death\", \"value\": 1000}}\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        result = rest_query(\"cases\", {\n",
    "            \"filters\": json.dumps(filters),\n",
    "            \"size\": \"0\"\n",
    "        })\n",
    "        \n",
    "        count = result[\"data\"][\"pagination\"][\"total\"]\n",
    "        print(f\"✅ EV-M07: Found {count} TCGA-OV cases with days_to_death < 1000\")\n",
    "        \n",
    "        results[\"EV-M07\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"{count} TCGA-OV cases with days_to_death < 1000\",\n",
    "            \"time\": time.time() - start\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-M07 Failed: {e}\")\n",
    "        results[\"EV-M07\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_M07()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23d01e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EV-M08: Found 1 LUAD Stage III cases with 77 files\n",
      "  Sample cases:\n",
      "    Case TCGA-95-7947: 77 files\n"
     ]
    }
   ],
   "source": [
    "# EV-M08: In the GDC database, retrieve case IDs and their associated file IDs for patients that meet BOTH criteria: (1) belong to the TCGA-LUAD project, AND (2) have a diagnosis with AJCC pathologic stage equal to Stage III only\n",
    "# Complex relationship mapping (stage-specific cases with file associations) \n",
    "def eval_M08():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        filters = {\n",
    "            \"op\": \"and\",\n",
    "            \"content\": [\n",
    "                {\"op\": \"=\", \"content\": {\"field\": \"project.project_id\", \"value\": \"TCGA-LUAD\"}},\n",
    "                {\"op\": \"=\", \"content\": {\"field\": \"diagnoses.ajcc_pathologic_stage\", \"value\": \"Stage III\"}}\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Get cases with Stage III LUAD\n",
    "        cases_result = rest_query(\"cases\", {\n",
    "            \"filters\": json.dumps(filters),\n",
    "            \"size\": \"1000\",\n",
    "            \"fields\": \"submitter_id,case_id,files.file_id\"\n",
    "        })\n",
    "        \n",
    "        stage_iii_cases = []\n",
    "        all_file_ids = []\n",
    "        \n",
    "        for case in cases_result[\"data\"][\"hits\"]:\n",
    "            case_files = []\n",
    "            files = case.get(\"files\", [])\n",
    "            \n",
    "            for file_info in files:\n",
    "                file_id = file_info.get(\"file_id\")\n",
    "                if file_id:\n",
    "                    case_files.append(file_id)\n",
    "                    all_file_ids.append(file_id)\n",
    "            \n",
    "            case_info = {\n",
    "                \"case_id\": case[\"case_id\"],\n",
    "                \"submitter_id\": case[\"submitter_id\"],\n",
    "                \"file_ids\": case_files,\n",
    "                \"file_count\": len(case_files)\n",
    "            }\n",
    "            stage_iii_cases.append(case_info)\n",
    "        \n",
    "        cases_count = len(stage_iii_cases)\n",
    "        total_files = len(all_file_ids)\n",
    "        \n",
    "        print(f\"✅ EV-M08: Found {cases_count} LUAD Stage III cases with {total_files} files\")\n",
    "        \n",
    "        if stage_iii_cases:\n",
    "            print(f\"  Sample cases:\")\n",
    "            for case in stage_iii_cases[:3]:\n",
    "                print(f\"    Case {case['submitter_id']}: {case['file_count']} files\")\n",
    "        \n",
    "        results[\"EV-M08\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"{cases_count} LUAD Stage III cases with {total_files} files\",\n",
    "            \"data\": {\"cases\": stage_iii_cases, \"total_files\": total_files},\n",
    "            \"time\": time.time() - start\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-M08 Failed: {e}\")\n",
    "        results[\"EV-M08\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_M08()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6271bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EV-M09: Found 21 projects with more than 500 cases:\n",
      "  FM-AD: 18,004 cases\n",
      "  CCDI-MCI: 3,093 cases\n",
      "  TARGET-AML: 2,492 cases\n",
      "  CPTAC-3: 1,683 cases\n",
      "  TARGET-ALL-P2: 1,587 cases\n",
      "  MP2PRT-ALL: 1,510 cases\n",
      "  TARGET-NBL: 1,132 cases\n",
      "  TCGA-BRCA: 1,098 cases\n",
      "  MMRF-COMMPASS: 995 cases\n",
      "  BEATAML1.0-COHORT: 826 cases\n",
      "  HCMI-CMDC: 804 cases\n",
      "  TARGET-WT: 652 cases\n",
      "  TCGA-GBM: 617 cases\n",
      "  TCGA-OV: 608 cases\n",
      "  TCGA-LUAD: 585 cases\n",
      "  TCGA-UCEC: 560 cases\n",
      "  TCGA-KIRC: 537 cases\n",
      "  TCGA-HNSC: 528 cases\n",
      "  TCGA-LGG: 516 cases\n",
      "  TCGA-THCA: 507 cases\n",
      "  TCGA-LUSC: 504 cases\n"
     ]
    }
   ],
   "source": [
    "# EV-M09: In the GDC database, list all projects that have more than 500 cases\n",
    "# Aggregation with threshold filtering\n",
    "def eval_M09():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        result = rest_query(\"cases\", {\n",
    "            \"size\": \"0\",\n",
    "            \"facets\": \"project.project_id\"\n",
    "        })\n",
    "        \n",
    "        # Get project counts and filter those > 500\n",
    "        large_projects = []\n",
    "        for bucket in result[\"data\"][\"aggregations\"][\"project.project_id\"][\"buckets\"]:\n",
    "            project = bucket[\"key\"]\n",
    "            count = bucket[\"doc_count\"]\n",
    "            if count > 500:\n",
    "                large_projects.append((project, count))\n",
    "        \n",
    "        # Sort by count descending\n",
    "        large_projects.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(f\"✅ EV-M09: Found {len(large_projects)} projects with more than 500 cases:\")\n",
    "        for project, count in large_projects:\n",
    "            print(f\"  {project}: {count:,} cases\")\n",
    "        \n",
    "        results[\"EV-M09\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"{len(large_projects)} projects with > 500 cases\",\n",
    "            \"data\": large_projects,\n",
    "            \"time\": time.time() - start\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-M09 Failed: {e}\")\n",
    "        results[\"EV-M09\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_M09()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43fdd150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EV-M10: Processed 504 TCGA-LUSC cases\n",
      "  Found 224 valid smoking duration records\n",
      "  Smoking years distribution:\n",
      "    0-10 years: 2 cases\n",
      "    10-20 years: 7 cases\n",
      "    20-30 years: 34 cases\n",
      "    30-40 years: 46 cases\n",
      "    40-50 years: 69 cases\n",
      "    50-100 years: 66 cases\n"
     ]
    }
   ],
   "source": [
    "# EV-M10: In the GDC database, count valid smoking duration records and the distribution of years of smoking for TCGA-LUSC project cases\n",
    "# Domain-specific analysis (smoking duration distribution)\n",
    "def eval_M10():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        # Use GraphQL to get exposure data\n",
    "        query = \"\"\"\n",
    "        query LUSCSmokingData($filters: FiltersArgument) {\n",
    "          viewer {\n",
    "            repository {\n",
    "              cases {\n",
    "                hits(first: 600, filters: $filters) {\n",
    "                  edges {\n",
    "                    node {\n",
    "                      case_id\n",
    "                      exposures {\n",
    "                        hits {\n",
    "                          edges {\n",
    "                            node {\n",
    "                              tobacco_smoking_onset_year\n",
    "                              tobacco_smoking_quit_year\n",
    "                            }\n",
    "                          }\n",
    "                        }\n",
    "                      }\n",
    "                    }\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "        \"\"\"\n",
    "        \n",
    "        variables = {\n",
    "            \"filters\": {\n",
    "                \"op\": \"=\",\n",
    "                \"content\": {\n",
    "                    \"field\": \"project.project_id\",\n",
    "                    \"value\": \"TCGA-LUSC\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        result = graphql_query(query, variables)\n",
    "        if result:\n",
    "            # Process exposure data\n",
    "            smoking_years = []\n",
    "            cases_processed = 0\n",
    "            \n",
    "            for case_edge in result[\"data\"][\"viewer\"][\"repository\"][\"cases\"][\"hits\"][\"edges\"]:\n",
    "                case_node = case_edge.get(\"node\", {})\n",
    "                exposures = case_node.get(\"exposures\", {}).get(\"hits\", {}).get(\"edges\", [])\n",
    "                \n",
    "                for exp_edge in exposures:\n",
    "                    exp = exp_edge.get(\"node\", {})\n",
    "                    onset = exp.get(\"tobacco_smoking_onset_year\")\n",
    "                    quit = exp.get(\"tobacco_smoking_quit_year\")\n",
    "                    \n",
    "                    if onset and quit:\n",
    "                        years = quit - onset\n",
    "                        if years > 0:\n",
    "                            smoking_years.append(years)\n",
    "                \n",
    "                cases_processed += 1\n",
    "            \n",
    "            print(f\"✅ EV-M10: Processed {cases_processed} TCGA-LUSC cases\")\n",
    "            print(f\"  Found {len(smoking_years)} valid smoking duration records\")\n",
    "            \n",
    "            if smoking_years:\n",
    "                # Create distribution bins\n",
    "                bins = [0, 10, 20, 30, 40, 50, 100]\n",
    "                bin_counts = [0] * (len(bins) - 1)\n",
    "                \n",
    "                for years in smoking_years:\n",
    "                    for i in range(len(bins) - 1):\n",
    "                        if bins[i] <= years < bins[i+1]:\n",
    "                            bin_counts[i] += 1\n",
    "                            break\n",
    "                \n",
    "                print(f\"  Smoking years distribution:\")\n",
    "                for i in range(len(bins)-1):\n",
    "                    print(f\"    {bins[i]}-{bins[i+1]} years: {bin_counts[i]} cases\")\n",
    "            \n",
    "            results[\"EV-M10\"] = {\n",
    "                \"status\": \"success\",\n",
    "                \"result\": f\"Smoking duration distribution for TCGA-LUSC\",\n",
    "                \"data\": {\"smoking_years\": smoking_years, \"cases_processed\": cases_processed},\n",
    "                \"time\": time.time() - start\n",
    "            }\n",
    "        else:\n",
    "            results[\"EV-M10\"] = {\"status\": \"error\", \"error\": \"GraphQL query failed\", \"time\": time.time() - start}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-M10 Failed: {e}\")\n",
    "        results[\"EV-M10\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_M10()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d704eb",
   "metadata": {},
   "source": [
    "### COMPLEX COHORTS QUERIES (High Complexity)\n",
    "\n",
    "These queries require multi-step reasoning, multiple entity relationships, or sophisticated filtering to define patient/sample cohorts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7370054f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EV-H01: Found 798 WGS files > 50GB for TCGA-GBM\n"
     ]
    }
   ],
   "source": [
    "# EV-H01: In the GDC database, count files that meet ALL three criteria: (1) TCGA-GBM project, (2) WGS experimental strategy, AND (3) file size > 50 GB\n",
    "# Multiple filters with range (project + strategy + file_size)\n",
    "def eval_H01():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        filters = {\n",
    "            \"op\": \"and\",\n",
    "            \"content\": [\n",
    "                {\"op\": \"=\", \"content\": {\"field\": \"cases.project.project_id\", \"value\": \"TCGA-GBM\"}},\n",
    "                {\"op\": \"=\", \"content\": {\"field\": \"experimental_strategy\", \"value\": \"WGS\"}},\n",
    "                {\"op\": \">\", \"content\": {\"field\": \"file_size\", \"value\": 53687091200}}  # 50 GB in bytes\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        result = rest_query(\"files\", {\n",
    "            \"filters\": json.dumps(filters),\n",
    "            \"size\": \"0\"\n",
    "        })\n",
    "        \n",
    "        count = result[\"data\"][\"pagination\"][\"total\"]\n",
    "        print(f\"✅ EV-H01: Found {count} WGS files > 50GB for TCGA-GBM\")\n",
    "        \n",
    "        results[\"EV-H01\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"{count} WGS files > 50GB\",\n",
    "            \"time\": time.time() - start\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-H01 Failed: {e}\")\n",
    "        results[\"EV-H01\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_H01()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a8bb983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EV-H02: Found 144 breast cancer female cases under 40 with RNA-Seq\n"
     ]
    }
   ],
   "source": [
    "# EV-H02: In the GDC database, count cases that meet ALL criteria: breast cancer, female, age < 40, RNA-Seq files\n",
    "# Multi-dimensional cohort (breast + female + age<40 + RNA-Seq)\n",
    "def eval_H02():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        filters = {\n",
    "            \"op\": \"and\",\n",
    "            \"content\": [\n",
    "                {\"op\": \"in\", \"content\": {\"field\": \"primary_site\", \"value\": [\"Breast\"]}},\n",
    "                {\"op\": \"=\", \"content\": {\"field\": \"demographic.gender\", \"value\": \"female\"}},\n",
    "                {\"op\": \"<\", \"content\": {\"field\": \"diagnoses.age_at_diagnosis\", \"value\": 14600}},  # 40 years in days\n",
    "                {\"op\": \"=\", \"content\": {\"field\": \"files.experimental_strategy\", \"value\": \"RNA-Seq\"}}\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        result = rest_query(\"cases\", {\n",
    "            \"filters\": json.dumps(filters),\n",
    "            \"size\": \"0\"\n",
    "        })\n",
    "        \n",
    "        count = result[\"data\"][\"pagination\"][\"total\"]\n",
    "        print(f\"✅ EV-H02: Found {count} breast cancer female cases under 40 with RNA-Seq\")\n",
    "        \n",
    "        results[\"EV-H02\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"{count} breast cancer female cases under 40 with RNA-Seq\",\n",
    "            \"time\": time.time() - start\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-H02 Failed: {e}\")\n",
    "        results[\"EV-H02\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_H02()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cd67f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EV-H03: Found 56 cases with alcohol history AND AJCC Stage II\n",
      "\n",
      "All Case IDs:\n",
      "================================================================================\n",
      "\n",
      "CPTAC-3 (31 cases):\n",
      "  C3N-03619 (94badce5-890f-468a-a689-7596a1acbd7d)\n",
      "  C3L-02669 (a162aaa1-45e3-4294-90c2-1e2cd8a8b356)\n",
      "  C3L-00981 (d84bfa68-63b1-4c84-848d-8b473638f970)\n",
      "  C3L-04354 (db9021f9-df04-48c4-b56c-499f49c5212f)\n",
      "  C3N-02296 (116436ce-6250-43b1-8fd2-2ebdb3ea9186)\n",
      "  C3L-02651 (3ef779a0-457a-4045-b04c-191b734b81a4)\n",
      "  C3L-04759 (3f92c203-a319-46a6-a627-8027070961fc)\n",
      "  C3N-04273 (701129b7-d95a-4fac-a9be-0d0da0642a81)\n",
      "  C3L-02802 (2a971d49-1fcc-40eb-a02b-0736a0929f43)\n",
      "  C3N-01648 (3a420b74-ac84-470e-99f1-811cbc37ac5e)\n",
      "  C3N-04280 (1f370a2d-7fbd-4fa5-8bb8-bdaa94c1ba9f)\n",
      "  C3N-03457 (1f9bd893-4a8c-47ae-aa59-c32b5a430575)\n",
      "  C3N-02789 (4d6794c9-25bc-47a0-ac2e-352d434b577c)\n",
      "  C3L-00994 (5119c0a8-d0ef-4ec2-b58c-0ff9e0c8f1db)\n",
      "  C3N-03458 (28d777f2-f4c8-4853-bd28-1bba94f2bfa6)\n",
      "  C3N-04275 (2dc5fc3a-4f92-4b1b-8a54-bd86bbdeac93)\n",
      "  C3L-00991 (61665776-139e-450f-bc64-eaf29bd7ff25)\n",
      "  C3N-00519 (eae77c25-2317-4ec4-8f21-3975ac9ab827)\n",
      "  C3L-01732 (51d42be6-879f-4471-99c4-0d8bdcf70612)\n",
      "  C3N-03013 (06a5212b-f025-4d72-b10f-9b0b91274f72)\n",
      "  C3N-03027 (39f5218a-5a5c-452a-916a-d840fa9757d8)\n",
      "  C3N-00953 (1570eaf1-9b92-4506-9df0-9ae9a704a731)\n",
      "  C3L-00908 (763e0702-8379-4b5e-95d1-a84f412c51e7)\n",
      "  C3L-00360 (b1114673-0f13-4265-98d8-21c5714d91a4)\n",
      "  C3N-01214 (f674a0fe-66bc-4b0f-a12c-e025655f8a64)\n",
      "  C3N-04279 (8ed163a6-eae6-4bf5-9b0c-80de5dd4935b)\n",
      "  C3N-00492 (920b70b3-265f-4c67-afe5-079b073cab03)\n",
      "  C3N-01651 (947a6de8-a1fe-41f3-9568-2311f9fa341b)\n",
      "  C3L-00413 (c4a660b0-7b34-4c80-98bb-0000e2b1c09a)\n",
      "  C3L-02617 (cc67e6be-8b13-4ccd-ab7b-3d8deb71b4dd)\n",
      "  C3N-03433 (cf958f8c-f1c7-4adb-ad0f-fab5133042ed)\n",
      "\n",
      "TCGA-ESCA (1 cases):\n",
      "  TCGA-LN-A4A6 (ffcfa005-a04f-458e-9d1d-86143dd823e5)\n",
      "\n",
      "TCGA-HNSC (24 cases):\n",
      "  TCGA-CV-7406 (2c6d6c93-fb6d-47f7-a868-5e9a82c75d4c)\n",
      "  TCGA-CQ-5323 (deefdd62-4d35-40c9-ad4c-0b593f35cff7)\n",
      "  TCGA-CV-7427 (c2bbb6f9-6f88-4a58-a15a-b887dfad34b4)\n",
      "  TCGA-CV-7180 (d2ca9a4d-c14c-40c0-871c-88794a02e4aa)\n",
      "  TCGA-CN-5358 (b4e0c62d-f2f6-4243-9e0f-ae2ad4ca4bb8)\n",
      "  TCGA-CV-7254 (f4343626-f677-4fe5-862b-8fb4a16262bf)\n",
      "  TCGA-CR-5249 (c7df3466-b9a7-4818-883b-d0cd08483570)\n",
      "  TCGA-CQ-7072 (d622bcab-5b5a-45a4-8c02-7bcfdbbb781c)\n",
      "  TCGA-MT-A67D (11c944fc-9a49-4c00-ab8c-da5dfd595244)\n",
      "  TCGA-D6-6823 (fbdab01c-191c-4aef-9451-ca3afec55fa1)\n",
      "  TCGA-CV-6961 (4075717b-2240-4842-a00a-0c4dbcb910c4)\n",
      "  TCGA-F7-A624 (46e51eb2-0c5e-457b-af1a-8bac1b8a8bea)\n",
      "  TCGA-CV-7242 (4b4247e2-4446-44f5-8573-4cea8bf69f8e)\n",
      "  TCGA-CV-A6JZ (4cacff9d-cc50-43a5-a227-16923ada7467)\n",
      "  TCGA-D6-8568 (5ed786f3-1d15-4079-bb8f-2f34ef305644)\n",
      "  TCGA-BA-A4II (2855bf40-e5e1-4519-b47a-327bfc275279)\n",
      "  TCGA-CV-7097 (9d0f5938-6a01-4c06-8536-dff834f7f2f9)\n",
      "  TCGA-BA-A6DE (116ad004-929d-4c8d-8eee-883d132e0fe5)\n",
      "  TCGA-HD-7917 (a40f1055-3dc4-4d01-930c-92cf314f73f8)\n",
      "  TCGA-CV-7101 (241d9310-9137-42dd-b28d-0dc50c44cb43)\n",
      "  TCGA-BA-5556 (70741b73-9683-42bd-87fc-6a021a70103b)\n",
      "  TCGA-CR-6470 (cd032ddb-55f2-4c77-8dcf-e4e630f7de6f)\n",
      "  TCGA-CV-6433 (d5eedfb5-4fa3-4a1e-ad0d-ea550b22a5ba)\n",
      "  TCGA-CV-7235 (2fbafcc5-896c-4e50-8956-a61540fc89be)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# EV-H03: In the GDC database, find cases with alcohol history AND AJCC Stage II\n",
    "# Complex cohort definition combining exposure history and clinical staging\n",
    "def eval_H03():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        filters = {\n",
    "            \"op\": \"and\",\n",
    "            \"content\": [\n",
    "                {\"op\": \"=\", \"content\": {\"field\": \"exposures.alcohol_history\", \"value\": \"Yes\"}},\n",
    "                {\"op\": \"=\", \"content\": {\"field\": \"diagnoses.ajcc_pathologic_stage\", \"value\": \"Stage II\"}}\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # First, get the total count\n",
    "        count_result = rest_query(\"cases\", {\n",
    "            \"filters\": json.dumps(filters),\n",
    "            \"size\": \"0\"\n",
    "        })\n",
    "        total_count = count_result[\"data\"][\"pagination\"][\"total\"]\n",
    "        \n",
    "        # Fetch all cases in batches\n",
    "        all_cases = []\n",
    "        size = 1000\n",
    "        from_idx = 0\n",
    "        \n",
    "        while from_idx < total_count:\n",
    "            result = rest_query(\"cases\", {\n",
    "                \"filters\": json.dumps(filters),\n",
    "                \"size\": str(size),\n",
    "                \"from\": str(from_idx),\n",
    "                \"fields\": \"submitter_id,case_id,project.project_id\"\n",
    "            })\n",
    "            \n",
    "            batch_cases = result[\"data\"][\"hits\"]\n",
    "            if not batch_cases:\n",
    "                break\n",
    "            \n",
    "            for case in batch_cases:\n",
    "                all_cases.append({\n",
    "                    \"case_id\": case[\"case_id\"],\n",
    "                    \"submitter_id\": case[\"submitter_id\"],\n",
    "                    \"project\": case.get(\"project\", {}).get(\"project_id\", \"Unknown\")\n",
    "                })\n",
    "            \n",
    "            from_idx += len(batch_cases)\n",
    "            if len(batch_cases) < size:\n",
    "                break\n",
    "        \n",
    "        count = len(all_cases)\n",
    "        print(f\"✅ EV-H03: Found {count} cases with alcohol history AND AJCC Stage II\")\n",
    "        \n",
    "        # Group by project\n",
    "        by_project = {}\n",
    "        for case in all_cases:\n",
    "            project = case[\"project\"]\n",
    "            if project not in by_project:\n",
    "                by_project[project] = []\n",
    "            by_project[project].append(case)\n",
    "        \n",
    "        # Display all cases grouped by project\n",
    "        print(f\"\\nAll Case IDs:\")\n",
    "        print(\"=\"*80)\n",
    "        for project in sorted(by_project.keys()):\n",
    "            cases_in_project = by_project[project]\n",
    "            print(f\"\\n{project} ({len(cases_in_project)} cases):\")\n",
    "            for case in cases_in_project:\n",
    "                print(f\"  {case['submitter_id']} ({case['case_id']})\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        results[\"EV-H03\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"{count} cases with alcohol history AND Stage II\",\n",
    "            \"data\": {\"cases\": all_cases},\n",
    "            \"time\": time.time() - start\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-H03 Failed: {e}\")\n",
    "        results[\"EV-H03\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_H03()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ff3259a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EV-H04: Found 62,935 files for 1,188 cases\n",
      "  Cases: Cancer-related deaths ≤50 years old\n"
     ]
    }
   ],
   "source": [
    "# EV-H04: In the GDC database, count files for cases with cancer-related death AND died ≤50 years\n",
    "# Multiple criteria with file counting\n",
    "def eval_H04():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        filters = {\n",
    "            \"op\": \"and\",\n",
    "            \"content\": [\n",
    "                {\"op\": \"=\", \"content\": {\"field\": \"demographic.cause_of_death\", \"value\": \"Cancer Related\"}},\n",
    "                {\"op\": \"<=\", \"content\": {\"field\": \"demographic.days_to_death\", \"value\": 18250}}  # 50 years in days\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Get cases\n",
    "        cases_result = rest_query(\"cases\", {\n",
    "            \"filters\": json.dumps(filters),\n",
    "            \"size\": \"0\"\n",
    "        })\n",
    "        cases_count = cases_result[\"data\"][\"pagination\"][\"total\"]\n",
    "        \n",
    "        # Get files for these cases\n",
    "        files_result = rest_query(\"files\", {\n",
    "            \"filters\": json.dumps({\n",
    "                \"op\": \"and\",\n",
    "                \"content\": [\n",
    "                    {\"op\": \"=\", \"content\": {\"field\": \"cases.demographic.cause_of_death\", \"value\": \"Cancer Related\"}},\n",
    "                    {\"op\": \"<=\", \"content\": {\"field\": \"cases.demographic.days_to_death\", \"value\": 18250}}\n",
    "                ]\n",
    "            }),\n",
    "            \"size\": \"0\"\n",
    "        })\n",
    "        files_count = files_result[\"data\"][\"pagination\"][\"total\"]\n",
    "        \n",
    "        print(f\"✅ EV-H04: Found {files_count:,} files for {cases_count:,} cases\")\n",
    "        print(f\"  Cases: Cancer-related deaths ≤50 years old\")\n",
    "        \n",
    "        results[\"EV-H04\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"{files_count} files for {cases_count} cases\",\n",
    "            \"data\": {\"cases_count\": cases_count, \"files_count\": files_count},\n",
    "            \"time\": time.time() - start\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-H04 Failed: {e}\")\n",
    "        results[\"EV-H04\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_H04()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4706fed2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 79\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m❌ EV-H05 Failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     77\u001b[0m         results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEV-H05\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(e), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m: time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start}\n\u001b[0;32m---> 79\u001b[0m \u001b[43meval_H05\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m, in \u001b[0;36meval_H05\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m filters \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mop\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     ]\n\u001b[1;32m     12\u001b[0m }\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Get total count first\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m count_result \u001b[38;5;241m=\u001b[39m \u001b[43mrest_query\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcases\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfilters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     18\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m total \u001b[38;5;241m=\u001b[39m count_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpagination\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Fetch all cases in batches\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 34\u001b[0m, in \u001b[0;36mrest_query\u001b[0;34m(endpoint, params)\u001b[0m\n\u001b[1;32m     31\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mGDC_API_BASE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     32\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m---> 34\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/work/ai-agent-evaluation/.venv/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/ai-agent-evaluation/.venv/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/ai-agent-evaluation/.venv/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/work/ai-agent-evaluation/.venv/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/work/ai-agent-evaluation/.venv/lib/python3.10/site-packages/requests/adapters.py:644\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    641\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    659\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/work/ai-agent-evaluation/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/work/ai-agent-evaluation/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:464\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    466\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/work/ai-agent-evaluation/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:1093\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[0;32m-> 1093\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mproxy_is_verified:\n",
      "File \u001b[0;32m~/work/ai-agent-evaluation/.venv/lib/python3.10/site-packages/urllib3/connection.py:753\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    752\u001b[0m     sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[0;32m--> 753\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    754\u001b[0m     server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[1;32m    755\u001b[0m     tls_in_tls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/work/ai-agent-evaluation/.venv/lib/python3.10/site-packages/urllib3/connection.py:198\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m:return: New socket connection.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 198\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/work/ai-agent-evaluation/.venv/lib/python3.10/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[1;32m     75\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# EV-H05: In the GDC database, find and list all cases that meet BOTH of these criteria: (1) have a documented family history where a relative's primary diagnosis was \"Breast Cancer\" (family_histories.relationship_primary_diagnosis = \"Breast Cancer\"), AND (2) have at least one associated file that was generated using the RNA-Seq experimental strategy (files.experimental_strategy = \"RNA-Seq\"). Return the case identifiers, total count, and breakdown by project.\n",
    "# Multi-entity join with family history and file type filtering\n",
    "def eval_H05():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        filters = {\n",
    "            \"op\": \"and\",\n",
    "            \"content\": [\n",
    "                {\"op\": \"=\", \"content\": {\"field\": \"family_histories.relationship_primary_diagnosis\", \"value\": \"Breast Cancer\"}},\n",
    "                {\"op\": \"=\", \"content\": {\"field\": \"files.experimental_strategy\", \"value\": \"RNA-Seq\"}}\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Get total count first\n",
    "        count_result = rest_query(\"cases\", {\n",
    "            \"filters\": json.dumps(filters),\n",
    "            \"size\": \"0\"\n",
    "        })\n",
    "        total = count_result[\"data\"][\"pagination\"][\"total\"]\n",
    "        \n",
    "        # Fetch all cases in batches\n",
    "        all_cases = []\n",
    "        size = 1000\n",
    "        from_idx = 0\n",
    "        \n",
    "        while from_idx < total:\n",
    "            result = rest_query(\"cases\", {\n",
    "                \"filters\": json.dumps(filters),\n",
    "                \"size\": str(size),\n",
    "                \"from\": str(from_idx),\n",
    "                \"fields\": \"case_id,submitter_id,project.project_id\"\n",
    "            })\n",
    "            \n",
    "            batch_cases = result[\"data\"][\"hits\"]\n",
    "            if not batch_cases:\n",
    "                break\n",
    "            \n",
    "            all_cases.extend(batch_cases)\n",
    "            from_idx += len(batch_cases)\n",
    "            \n",
    "            if len(batch_cases) < size:\n",
    "                break\n",
    "        \n",
    "        # Group by project\n",
    "        by_project = {}\n",
    "        for case in all_cases:\n",
    "            project = case.get('project', {}).get('project_id', 'Unknown')\n",
    "            if project not in by_project:\n",
    "                by_project[project] = []\n",
    "            by_project[project].append(case)\n",
    "        \n",
    "        print(f\"✅ EV-H05: Found {total:,} cases with family history of breast cancer AND RNA-Seq files\")\n",
    "        print(f\"\\n  Breakdown by project:\")\n",
    "        for project in sorted(by_project.keys()):\n",
    "            print(f\"    {project}: {len(by_project[project]):,} cases\")\n",
    "        \n",
    "        print(f\"\\n  All Case IDs:\")\n",
    "        for project in sorted(by_project.keys()):\n",
    "            print(f\"\\n  {project}:\")\n",
    "            for case in by_project[project]:\n",
    "                print(f\"    {case.get('submitter_id')} ({case.get('case_id')})\")\n",
    "        \n",
    "        results[\"EV-H05\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"{total} cases with family history of breast cancer AND RNA-Seq\",\n",
    "            \"data\": {\n",
    "                \"total\": total,\n",
    "                \"by_project\": {project: len(cases) for project, cases in by_project.items()},\n",
    "                \"cases\": [{\"case_id\": c.get('case_id'), \"submitter_id\": c.get('submitter_id'), \n",
    "                          \"project\": c.get('project', {}).get('project_id', 'Unknown')} \n",
    "                         for c in all_cases]\n",
    "            },\n",
    "            \"time\": time.time() - start\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-H05 Failed: {e}\")\n",
    "        results[\"EV-H05\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_H05()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e0dd0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EV-H06: Mean age at diagnosis for TCGA-COAD\n",
      "  Cases analyzed: 425\n",
      "  Mean age: 67.1 years (24499 days)\n"
     ]
    }
   ],
   "source": [
    "# EV-H06: In the GDC database, what is the mean age at diagnosis for TCGA-COAD cases? (Deduplicate multiple diagnoses per case)\n",
    "# Complex calculation with deduplication logic\n",
    "def eval_H06():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        filters = {\n",
    "            \"op\": \"=\",\n",
    "            \"content\": {\"field\": \"project.project_id\", \"value\": \"TCGA-COAD\"}\n",
    "        }\n",
    "        \n",
    "        # Get all cases with diagnoses\n",
    "        result = rest_query(\"cases\", {\n",
    "            \"filters\": json.dumps(filters),\n",
    "            \"fields\": \"case_id,diagnoses.age_at_diagnosis\",\n",
    "            \"size\": \"10000\"\n",
    "        })\n",
    "        \n",
    "        cases = result[\"data\"][\"hits\"]\n",
    "        total_cases = 0\n",
    "        total_age = 0\n",
    "        \n",
    "        # Deduplicate: take first diagnosis for each case\n",
    "        for case in cases:\n",
    "            diagnoses = case.get(\"diagnoses\", [])\n",
    "            if diagnoses and len(diagnoses) > 0:\n",
    "                # Take the first (earliest) diagnosis\n",
    "                age_at_diagnosis = diagnoses[0].get(\"age_at_diagnosis\")\n",
    "                if age_at_diagnosis is not None:\n",
    "                    total_age += age_at_diagnosis\n",
    "                    total_cases += 1\n",
    "        \n",
    "        # Convert from days to years\n",
    "        mean_age_days = total_age / total_cases if total_cases > 0 else 0\n",
    "        mean_age_years = mean_age_days / 365.25\n",
    "        \n",
    "        print(f\"✅ EV-H06: Mean age at diagnosis for TCGA-COAD\")\n",
    "        print(f\"  Cases analyzed: {total_cases:,}\")\n",
    "        print(f\"  Mean age: {mean_age_years:.1f} years ({mean_age_days:.0f} days)\")\n",
    "        \n",
    "        results[\"EV-H06\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"Mean age: {mean_age_years:.1f} years\",\n",
    "            \"data\": {\n",
    "                \"total_cases\": total_cases,\n",
    "                \"mean_age_days\": mean_age_days,\n",
    "                \"mean_age_years\": mean_age_years\n",
    "            },\n",
    "            \"time\": time.time() - start\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-H06 Failed: {e}\")\n",
    "        results[\"EV-H06\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_H06()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a771ca38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EV-H07: TCGA-OV diagnosis record analysis\n",
      "  Total cases: 608\n",
      "  0 diagnoses: 21 (3.5%)\n",
      "  1 diagnosis:  216 (35.5%)\n",
      "  Multiple:     371 (61.0%)\n"
     ]
    }
   ],
   "source": [
    "# EV-H07: In the GDC database, for TCGA-OV cases, how many have 0, 1, or multiple diagnosis records?\n",
    "# Complex diagnosis record analysis with categorization\n",
    "def eval_H07():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        filters = {\n",
    "            \"op\": \"=\",\n",
    "            \"content\": {\"field\": \"project.project_id\", \"value\": \"TCGA-OV\"}\n",
    "        }\n",
    "        \n",
    "        # Get all cases with diagnoses\n",
    "        result = rest_query(\"cases\", {\n",
    "            \"filters\": json.dumps(filters),\n",
    "            \"fields\": \"case_id,diagnoses.diagnosis_id\",\n",
    "            \"size\": \"10000\"\n",
    "        })\n",
    "        \n",
    "        cases = result[\"data\"][\"hits\"]\n",
    "        \n",
    "        # Categorize by diagnosis count\n",
    "        zero_diagnoses = 0\n",
    "        single_diagnosis = 0\n",
    "        multiple_diagnoses = 0\n",
    "        \n",
    "        for case in cases:\n",
    "            diagnoses = case.get(\"diagnoses\", [])\n",
    "            diagnosis_count = len(diagnoses)\n",
    "            \n",
    "            if diagnosis_count == 0:\n",
    "                zero_diagnoses += 1\n",
    "            elif diagnosis_count == 1:\n",
    "                single_diagnosis += 1\n",
    "            else:\n",
    "                multiple_diagnoses += 1\n",
    "        \n",
    "        total_cases = len(cases)\n",
    "        \n",
    "        print(f\"✅ EV-H07: TCGA-OV diagnosis record analysis\")\n",
    "        print(f\"  Total cases: {total_cases:,}\")\n",
    "        print(f\"  0 diagnoses: {zero_diagnoses:,} ({zero_diagnoses/total_cases*100:.1f}%)\")\n",
    "        print(f\"  1 diagnosis:  {single_diagnosis:,} ({single_diagnosis/total_cases*100:.1f}%)\")\n",
    "        print(f\"  Multiple:     {multiple_diagnoses:,} ({multiple_diagnoses/total_cases*100:.1f}%)\")\n",
    "        \n",
    "        results[\"EV-H07\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"0: {zero_diagnoses}, 1: {single_diagnosis}, Multiple: {multiple_diagnoses}\",\n",
    "            \"data\": {\n",
    "                \"total_cases\": total_cases,\n",
    "                \"zero_diagnoses\": zero_diagnoses,\n",
    "                \"single_diagnosis\": single_diagnosis,\n",
    "                \"multiple_diagnoses\": multiple_diagnoses\n",
    "            },\n",
    "            \"time\": time.time() - start\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-H07 Failed: {e}\")\n",
    "        results[\"EV-H07\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_H07()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "978bc8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EV-H08: Found 0 cases with WXS + RNA-Seq + Methylation\n",
      "  Criteria: Female, age 40-60\n",
      "  Top 3 projects:\n"
     ]
    }
   ],
   "source": [
    "# EV-H08: In the GDC database, identify cases with WXS AND RNA-Seq AND methylation data, female, age 40-60, show top 3 projects\n",
    "# Most complex query: 5 filter criteria + project aggregation + ranking\n",
    "def eval_H08():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        filters = {\n",
    "            \"op\": \"and\",\n",
    "            \"content\": [\n",
    "                {\"op\": \"=\", \"content\": {\"field\": \"demographic.gender\", \"value\": \"female\"}},\n",
    "                {\"op\": \">=\", \"content\": {\"field\": \"diagnoses.age_at_diagnosis\", \"value\": 14600}},  # 40 years\n",
    "                {\"op\": \"<=\", \"content\": {\"field\": \"diagnoses.age_at_diagnosis\", \"value\": 21900}},  # 60 years\n",
    "                {\n",
    "                    \"op\": \"and\",\n",
    "                    \"content\": [\n",
    "                        {\"op\": \"in\", \"content\": {\"field\": \"files.experimental_strategy\", \"value\": [\"WXS\"]}},\n",
    "                        {\"op\": \"in\", \"content\": {\"field\": \"files.experimental_strategy\", \"value\": [\"RNA-Seq\"]}},\n",
    "                        {\"op\": \"in\", \"content\": {\"field\": \"files.experimental_strategy\", \"value\": [\"Methylation Array\"]}}\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Get cases with project aggregation\n",
    "        result = rest_query(\"cases\", {\n",
    "            \"filters\": json.dumps(filters),\n",
    "            \"fields\": \"case_id,project.project_id\",\n",
    "            \"size\": \"10000\"\n",
    "        })\n",
    "        \n",
    "        cases = result[\"data\"][\"hits\"]\n",
    "        total_cases = len(cases)\n",
    "        \n",
    "        # Count by project\n",
    "        project_counts = {}\n",
    "        for case in cases:\n",
    "            project_id = case.get(\"project\", {}).get(\"project_id\", \"Unknown\")\n",
    "            project_counts[project_id] = project_counts.get(project_id, 0) + 1\n",
    "        \n",
    "        # Get top 3 projects\n",
    "        top_projects = sorted(project_counts.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "        \n",
    "        print(f\"✅ EV-H08: Found {total_cases:,} cases with WXS + RNA-Seq + Methylation\")\n",
    "        print(f\"  Criteria: Female, age 40-60\")\n",
    "        print(f\"  Top 3 projects:\")\n",
    "        for project_id, count in top_projects:\n",
    "            print(f\"    {project_id}: {count:,} cases\")\n",
    "        \n",
    "        results[\"EV-H08\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"{total_cases} cases, top 3 projects: {[p[0] for p in top_projects]}\",\n",
    "            \"data\": {\n",
    "                \"total_cases\": total_cases,\n",
    "                \"top_projects\": [{\"project_id\": p[0], \"count\": p[1]} for p in top_projects],\n",
    "                \"all_projects\": project_counts\n",
    "            },\n",
    "            \"time\": time.time() - start\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-H08 Failed: {e}\")\n",
    "        results[\"EV-H08\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_H08()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0275a056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Finding cases with both CNV and SSM data...\n",
      "  CNV cases: 17,751\n",
      "  CNV cases: 17,751\n",
      "  SSM cases: 40,661\n",
      "  Cases with BOTH: 1,926\n",
      "  SSM cases: 40,661\n",
      "  Cases with BOTH: 1,926\n"
     ]
    }
   ],
   "source": [
    "# EV-H09: In the GDC database, count cases that have files with BOTH data categories: (1) Copy Number Variation data, AND (2) Simple Nucleotide Variation data\n",
    "# Multi-entity intersection (cases with both CNV AND SSM) - COMPLEX & TIME-CONSUMING\n",
    "def eval_H09():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        print(\"🚀 Finding cases with both CNV and SSM data...\")\n",
    "        \n",
    "        def fetch_case_ids(data_category, max_cases=20000):\n",
    "            filters = {\n",
    "                \"op\": \"=\",\n",
    "                \"content\": {\n",
    "                    \"field\": \"files.data_category\",\n",
    "                    \"value\": data_category\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            count_result = rest_query(\"cases\", {\n",
    "                \"filters\": json.dumps(filters),\n",
    "                \"size\": \"0\"\n",
    "            })\n",
    "            total = count_result[\"data\"][\"pagination\"][\"total\"]\n",
    "            \n",
    "            case_ids = set()\n",
    "            size = 1000\n",
    "            from_idx = 0\n",
    "            \n",
    "            while from_idx < min(total, max_cases):\n",
    "                result = rest_query(\"cases\", {\n",
    "                    \"filters\": json.dumps(filters),\n",
    "                    \"size\": str(size),\n",
    "                    \"from\": str(from_idx),\n",
    "                    \"fields\": \"submitter_id\"\n",
    "                })\n",
    "                \n",
    "                batch = result[\"data\"][\"hits\"]\n",
    "                if not batch:\n",
    "                    break\n",
    "                \n",
    "                for case in batch:\n",
    "                    case_ids.add(case[\"submitter_id\"])\n",
    "                \n",
    "                from_idx += len(batch)\n",
    "                if len(batch) < size:\n",
    "                    break\n",
    "            \n",
    "            return case_ids, total\n",
    "        \n",
    "        # Fetch CNV and SSM cases\n",
    "        cnv_cases, cnv_total = fetch_case_ids(\"Copy Number Variation\")\n",
    "        print(f\"  CNV cases: {cnv_total:,}\")\n",
    "        \n",
    "        ssm_cases, ssm_total = fetch_case_ids(\"Simple Nucleotide Variation\")\n",
    "        print(f\"  SSM cases: {ssm_total:,}\")\n",
    "        \n",
    "        # Find intersection\n",
    "        both_cases = cnv_cases.intersection(ssm_cases)\n",
    "        both_count = len(both_cases)\n",
    "        \n",
    "        print(f\"  Cases with BOTH: {both_count:,}\")\n",
    "        \n",
    "        results[\"EV-H09\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"{both_count} cases with both CNV and SSM\",\n",
    "            \"data\": {\n",
    "                \"both_count\": both_count,\n",
    "                \"cnv_count\": cnv_total,\n",
    "                \"ssm_count\": ssm_total\n",
    "            },\n",
    "            \"time\": time.time() - start\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-H09 Failed: {e}\")\n",
    "        results[\"EV-H09\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_H09()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "797b9353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Finding cases with both WXS and RNA-Seq files...\n",
      "============================================================\n",
      "  📈 Total cases with WXS OR RNA-Seq: 27,151\n",
      "  📈 Total cases with WXS OR RNA-Seq: 27,151\n",
      "\n",
      "🎯 RESULTS:\n",
      "  Cases with WXS: 22,354\n",
      "  Cases with RNA-Seq: 22,182\n",
      "  Cases with BOTH: 17,422\n",
      "\n",
      "🎯 RESULTS:\n",
      "  Cases with WXS: 22,354\n",
      "  Cases with RNA-Seq: 22,182\n",
      "  Cases with BOTH: 17,422\n"
     ]
    }
   ],
   "source": [
    "# EV-H10: In the GDC database, list cases that have both WXS and RNA-Seq files\n",
    "# Multi-entity intersection (cases with both WXS AND RNA-Seq) - COMPLEX & TIME-CONSUMING\n",
    "def eval_H10():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        print(\"🚀 Finding cases with both WXS and RNA-Seq files...\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Step 1: Get cases with WXS OR RNA-Seq\n",
    "        filters = {\n",
    "            \"op\": \"or\",\n",
    "            \"content\": [\n",
    "                {\"op\": \"=\", \"content\": {\"field\": \"files.experimental_strategy\", \"value\": \"WXS\"}},\n",
    "                {\"op\": \"=\", \"content\": {\"field\": \"files.experimental_strategy\", \"value\": \"RNA-Seq\"}}\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Get total count\n",
    "        count_result = rest_query(\"cases\", {\n",
    "            \"filters\": json.dumps(filters),\n",
    "            \"size\": \"0\"\n",
    "        })\n",
    "        total_relevant = count_result[\"data\"][\"pagination\"][\"total\"]\n",
    "        print(f\"  📈 Total cases with WXS OR RNA-Seq: {total_relevant:,}\")\n",
    "        \n",
    "        # Step 2: Process cases to find intersection\n",
    "        cases_with_both = []\n",
    "        wxs_cases = set()\n",
    "        rnaseq_cases = set()\n",
    "        \n",
    "        # Fetch in batches\n",
    "        size = 1000\n",
    "        from_idx = 0\n",
    "        \n",
    "        while from_idx < total_relevant:\n",
    "            result = rest_query(\"cases\", {\n",
    "                \"filters\": json.dumps(filters),\n",
    "                \"size\": str(size),\n",
    "                \"from\": str(from_idx),\n",
    "                \"fields\": \"submitter_id,case_id,files.experimental_strategy\"\n",
    "            })\n",
    "            \n",
    "            batch_cases = result[\"data\"][\"hits\"]\n",
    "            if not batch_cases:\n",
    "                break\n",
    "            \n",
    "            for case in batch_cases:\n",
    "                files = case.get(\"files\", [])\n",
    "                case_strategies = set()\n",
    "                \n",
    "                for file_info in files:\n",
    "                    strategy = file_info.get(\"experimental_strategy\")\n",
    "                    if strategy in [\"WXS\", \"RNA-Seq\"]:\n",
    "                        case_strategies.add(strategy)\n",
    "                \n",
    "                case_id = case[\"submitter_id\"]\n",
    "                if \"WXS\" in case_strategies:\n",
    "                    wxs_cases.add(case_id)\n",
    "                if \"RNA-Seq\" in case_strategies:\n",
    "                    rnaseq_cases.add(case_id)\n",
    "                \n",
    "                if \"WXS\" in case_strategies and \"RNA-Seq\" in case_strategies:\n",
    "                    cases_with_both.append(case_id)\n",
    "            \n",
    "            from_idx += len(batch_cases)\n",
    "            if len(batch_cases) < size:\n",
    "                break\n",
    "        \n",
    "        count = len(cases_with_both)\n",
    "        \n",
    "        print(f\"\\n🎯 RESULTS:\")\n",
    "        print(f\"  Cases with WXS: {len(wxs_cases):,}\")\n",
    "        print(f\"  Cases with RNA-Seq: {len(rnaseq_cases):,}\")\n",
    "        print(f\"  Cases with BOTH: {count:,}\")\n",
    "        \n",
    "        results[\"EV-H09\"] = {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": f\"{count} cases with both WXS and RNA-Seq\",\n",
    "            \"data\": {\n",
    "                \"both_count\": count,\n",
    "                \"wxs_count\": len(wxs_cases),\n",
    "                \"rnaseq_count\": len(rnaseq_cases)\n",
    "            },\n",
    "            \"time\": time.time() - start\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EV-H09 Failed: {e}\")\n",
    "        results[\"EV-H09\"] = {\"status\": \"error\", \"error\": str(e), \"time\": time.time() - start}\n",
    "\n",
    "eval_H10()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agent-evaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
